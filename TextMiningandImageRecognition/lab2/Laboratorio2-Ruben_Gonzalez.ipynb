{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text mining and Image Recognition: Laboratorio 2\n",
    "#### Ruben Gonzalez 20003314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ruben\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    C:\\Users\\ruben\\AppData\\Local\\Continuum\\anaconda3\\envs\\Galileo-Python\\lib\\site-packages\\es_core_news_sm\n",
      "    -->\n",
      "    C:\\Users\\ruben\\AppData\\Local\\Continuum\\anaconda3\\envs\\Galileo-Python\\lib\\site-packages\\spacy\\data\\es_core_news_sm\n",
      "\n",
      "    You can now load the model via spacy.load('es_core_news_sm')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema #1:\n",
    "Utilizando el codigo trabajado durante la sesion de laboratorio construya una funcion que le permita realizar la clasicacion de un texto aleatorio proporcinado como argumento a dicha funcion. Su funcion debe utilzar los procedimientos y modelos de Machine Learning que se generaron en clase, si usted desea puede reescribir los procedimientos para volverlos mas eficientes, el objetivo es que se pueda realizar la prediccion de ham o spam para cualquier string dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ir hasta el punto de jurong, loco .. Disponibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>lar bien ... Bromas WIF u oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Entrada libre en una imagen de obsequio 2 wkly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>T Dun decir hor tan temprano ... t r ya contin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah no creo que vaya a USF, que vive por aquí,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>spam</td>\n",
       "      <td>Esta es la segunda vez que hemos intentado 2 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Se √º b explanada de ir a casa fr?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lástima, * estaba en el estado de ánimo para e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>El chico hizo un poco de putear pero actuaba c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Su fiel a su nombre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "1      ham  Ir hasta el punto de jurong, loco .. Disponibl...\n",
       "2      ham                  lar bien ... Bromas WIF u oni ...\n",
       "3     spam  Entrada libre en una imagen de obsequio 2 wkly...\n",
       "4      ham  T Dun decir hor tan temprano ... t r ya contin...\n",
       "5      ham  Nah no creo que vaya a USF, que vive por aquí,...\n",
       "...    ...                                                ...\n",
       "5568  spam  Esta es la segunda vez que hemos intentado 2 d...\n",
       "5569   ham                 Se √º b explanada de ir a casa fr?\n",
       "5570   ham  Lástima, * estaba en el estado de ánimo para e...\n",
       "5571   ham  El chico hizo un poco de putear pero actuaba c...\n",
       "5572   ham                          Rofl. Su fiel a su nombre\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamDB = pd.read_csv('es_spam.csv', error_bad_lines=False, sep=\",\",  names=['label', 'message'])\n",
    "spamDB = spamDB.iloc[1:]\n",
    "spamDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corpus = spamDB.mensaje\n",
    "corpus = spamDB.message\n",
    "\n",
    "spamDB.label.value_counts()/len(spamDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1494, 2), (747, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham = spamDB[spamDB['label'] == 'ham']\n",
    "spam = spamDB[spamDB['label'] == 'spam']\n",
    "ham = ham.sample(2*spam.shape[0])\n",
    "ham.shape, spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2241, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ham.append(spam, ignore_index=True)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dataset.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizacion \n",
    "import re, string\n",
    "def StrNomralization(corpus):\n",
    "    newCorpus = []\n",
    "    for i, doc in enumerate(corpus):\n",
    "        newCorpus.append(re.sub(r'[^a-zA-Z0-9\\s{1}áéíóúü]', '', doc).lower().strip().replace('     ', '').rstrip('\\r\\n').rstrip(\"\\n\"))\n",
    "    return newCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTrainCorpus = StrNomralization(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizacion\n",
    "def tokenizationV1(newCorpus):\n",
    "    documents = []\n",
    "    for i, doc in enumerate(newCorpus):\n",
    "        documents.append(nlp(doc))\n",
    "    return documents\n",
    "\n",
    "newTrainCorpus = tokenizationV1(newTrainCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords\n",
    "def removeStops(documents):\n",
    "    newDoc = []\n",
    "    for index, doc in enumerate(documents):\n",
    "        s = \"\"\n",
    "        for token in doc:\n",
    "            if ((token.is_stop == False) ): #√\n",
    "                s = s + token.text + \" \"\n",
    "          #print(s)\n",
    "        newDoc.append(s.strip())\n",
    "    return newDoc\n",
    "\n",
    "newTrainCorpus = removeStops(newTrainCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming y lematizacion\n",
    "\n",
    "def stemmingLemmating(newDoc):\n",
    "    documents = []\n",
    "    for doc in newDoc:\n",
    "        #print(doc)\n",
    "        documents.append(nlp(doc))\n",
    "\n",
    "\n",
    "    newDoc = []\n",
    "    for index, doc in enumerate(documents):\n",
    "        s = \"\"\n",
    "        for token in doc:\n",
    "            s = s + token.lemma_ + \" \"\n",
    "        newDoc.append(s.strip())\n",
    "    return newDoc\n",
    "\n",
    "readyTrainCorpus = stemmingLemmating(newTrainCorpus)\n",
    "newTrainCorpus = stemmingLemmating(newTrainCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#medida tf\n",
    "def listToString(s):  \n",
    "    str1 = \"\"  \n",
    "    for ele in s:  \n",
    "        str1 += ele + \" \"\n",
    "    return str1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTrash(newDoc):\n",
    "    mainStr = listToString(newDoc).strip().split(' ')\n",
    "    #mainStr = [x for x in mainStr if (len(x) >= 0)] #camviar esto\n",
    "    return mainStr\n",
    "\n",
    "newTrainCorpus = removeTrash(newTrainCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculamos la frecuencia de cada termin\n",
    "newTrainCorpus = set(newTrainCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainColumns = list(newTrainCorpus)\n",
    "trainRows = range(0, len(readyTrainCorpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateEmptyTf(cols, rows):\n",
    "    outDf = pd.DataFrame(index=rows, columns=cols)\n",
    "    outDf = outDf.fillna(0) # with 0s rather than NaNs\n",
    "\n",
    "    return outDf\n",
    "\n",
    "tfTrain = generateEmptyTf(trainColumns, trainRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculo de tf\n",
    "\n",
    "def calculoTf(newDoc, df):\n",
    "    documents = []\n",
    "\n",
    "    for doc in newDoc:\n",
    "        documents.append(nlp(doc))\n",
    "    for index, doc in enumerate(documents):\n",
    "        bagOfWordsLen = len(doc)\n",
    "        for word in doc:\n",
    "            try:\n",
    "                colIndex = list(df.columns).index(word.text)\n",
    "                #print(colIndex)\n",
    "                df.iloc[index, colIndex] = df.iloc[index, colIndex] + 1\n",
    "                #termFreqTemp.iloc[index, colIndex] = termFreqTemp.iloc[index, colIndex] + 1\n",
    "            except Exception as e: \n",
    "            #print(e)\n",
    "            #print(\"error\")\n",
    "            #print(doc)\n",
    "                pass\n",
    "        df.iloc[index, :] = df.iloc[index, :]/bagOfWordsLen\n",
    "\n",
    "    #for index, doc in enumerate(documents):\n",
    "    #  df.iloc[index, :] = df.iloc[index, :]/df.shape[1]\n",
    "    return df\n",
    "\n",
    "\n",
    "trainTf = calculoTf(readyTrainCorpus, tfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculoIdf(df):\n",
    "    N = df.shape[0]\n",
    "    #print(N)\n",
    "    valX = (N/df.astype(bool).sum(axis=0))\n",
    "    #print(df.astype(bool))\n",
    "    idfValue = pd.Series(np.log(valX))\n",
    "    return idfValue\n",
    "\n",
    "trainIdf = calculoIdf(trainTf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>monthlysubscription</th>\n",
       "      <th>reservar</th>\n",
       "      <th>kthen</th>\n",
       "      <th>princegn</th>\n",
       "      <th>balanza</th>\n",
       "      <th>gasolina</th>\n",
       "      <th>negar</th>\n",
       "      <th>2kbsubject</th>\n",
       "      <th>reemplazar</th>\n",
       "      <th>...</th>\n",
       "      <th>meetins</th>\n",
       "      <th>tonificar</th>\n",
       "      <th>ard</th>\n",
       "      <th>bluray</th>\n",
       "      <th>bcz</th>\n",
       "      <th>poli</th>\n",
       "      <th>cutefrnd</th>\n",
       "      <th>directamente</th>\n",
       "      <th>yday</th>\n",
       "      <th>extremo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2241 rows × 5365 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           monthlysubscription  reservar  kthen  princegn  balanza  gasolina  \\\n",
       "0     0.0                  0.0       0.0    0.0       0.0      0.0       0.0   \n",
       "1     0.0                  0.0       0.0    0.0       0.0      0.0       0.0   \n",
       "2     0.0                  0.0       0.0    0.0       0.0      0.0       0.0   \n",
       "3     0.0                  0.0       0.0    0.0       0.0      0.0       0.0   \n",
       "4     0.0                  0.0       0.0    0.0       0.0      0.0       0.0   \n",
       "...   ...                  ...       ...    ...       ...      ...       ...   \n",
       "2236  0.0                  0.0       0.0    0.0       0.0      0.0       0.0   \n",
       "2237  0.0                  0.0       0.0    0.0       0.0      0.0       0.0   \n",
       "2238  0.0                  0.0       0.0    0.0       0.0      0.0       0.0   \n",
       "2239  0.0                  0.0       0.0    0.0       0.0      0.0       0.0   \n",
       "2240  0.0                  0.0       0.0    0.0       0.0      0.0       0.0   \n",
       "\n",
       "      negar  2kbsubject  reemplazar  ...  meetins  tonificar  ard  bluray  \\\n",
       "0       0.0         0.0         0.0  ...      0.0        0.0  0.0     0.0   \n",
       "1       0.0         0.0         0.0  ...      0.0        0.0  0.0     0.0   \n",
       "2       0.0         0.0         0.0  ...      0.0        0.0  0.0     0.0   \n",
       "3       0.0         0.0         0.0  ...      0.0        0.0  0.0     0.0   \n",
       "4       0.0         0.0         0.0  ...      0.0        0.0  0.0     0.0   \n",
       "...     ...         ...         ...  ...      ...        ...  ...     ...   \n",
       "2236    0.0         0.0         0.0  ...      0.0        0.0  0.0     0.0   \n",
       "2237    0.0         0.0         0.0  ...      0.0        0.0  0.0     0.0   \n",
       "2238    0.0         0.0         0.0  ...      0.0        0.0  0.0     0.0   \n",
       "2239    0.0         0.0         0.0  ...      0.0        0.0  0.0     0.0   \n",
       "2240    0.0         0.0         0.0  ...      0.0        0.0  0.0     0.0   \n",
       "\n",
       "      bcz  poli  cutefrnd  directamente  yday  extremo  \n",
       "0     0.0   0.0       0.0           0.0   0.0      0.0  \n",
       "1     0.0   0.0       0.0           0.0   0.0      0.0  \n",
       "2     0.0   0.0       0.0           0.0   0.0      0.0  \n",
       "3     0.0   0.0       0.0           0.0   0.0      0.0  \n",
       "4     0.0   0.0       0.0           0.0   0.0      0.0  \n",
       "...   ...   ...       ...           ...   ...      ...  \n",
       "2236  0.0   0.0       0.0           0.0   0.0      0.0  \n",
       "2237  0.0   0.0       0.0           0.0   0.0      0.0  \n",
       "2238  0.0   0.0       0.0           0.0   0.0      0.0  \n",
       "2239  0.0   0.0       0.0           0.0   0.0      0.0  \n",
       "2240  0.0   0.0       0.0           0.0   0.0      0.0  \n",
       "\n",
       "[2241 rows x 5365 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculo tf-idf\n",
    "tfIdfTrain = trainTf.mul(trainIdf, axis=1)\n",
    "tfIdfTrain = tfIdfTrain.fillna(0)\n",
    "tfIdfTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamos el modelo SVC que fue el que mejor exactitud mostro en el ejercicio en clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfIdfTrain, dataset['label'], test_size=0.3, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    if(x == \"ham\"):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(map(encode, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1568, 5365)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107      ham\n",
       "1005     ham\n",
       "565      ham\n",
       "564      ham\n",
       "39       ham\n",
       "        ... \n",
       "1770    spam\n",
       "82       ham\n",
       "2116    spam\n",
       "1664    spam\n",
       "988      ham\n",
       "Name: label, Length: 673, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svmc = SVC(kernel='linear')\n",
    "svmc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = X_test.fillna(0)\n",
    "y_pred_svm = svmc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107      ham\n",
       "1005     ham\n",
       "565      ham\n",
       "564      ham\n",
       "39       ham\n",
       "        ... \n",
       "1770    spam\n",
       "82       ham\n",
       "2116    spam\n",
       "1664    spam\n",
       "988      ham\n",
       "Name: label, Length: 673, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[427,  34],\n",
       "       [ 13, 199]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_test = list(map(encode, y_test))\n",
    "confusion_matrix(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9301634472511144"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(x):\n",
    "  if(x == 0):\n",
    "    return \"ham\"\n",
    "  else:\n",
    "    return \"spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de funcion para clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrediceSpam(texto):\n",
    "    Normaliza = StrNomralization(texto)\n",
    "    NuevoCorpus = tokenizationV1(Normaliza)\n",
    "    NuevoCorpus = removeStops(NuevoCorpus)\n",
    "    readyTrainCorpus = stemmingLemmating(NuevoCorpus)\n",
    "    NuevoCorpus = stemmingLemmating(NuevoCorpus)\n",
    "    NuevoCorpus = removeTrash(NuevoCorpus)\n",
    "    NuevoCorpus = set(NuevoCorpus)\n",
    "    \n",
    "    Columns = list(NuevoCorpus)\n",
    "    \n",
    "    #Se obtienen los pesos de la frase por palabra\n",
    "    tfTrain = generateEmptyTf(Columns, [1])\n",
    "    trainTf = calculoTf(readyTrainCorpus, tfTrain)\n",
    "    \n",
    "    #Se obtiene una row en blanco de la longitud de los dataset de training\n",
    "    tfTrainGeneral = generateEmptyTf(trainColumns, [1])\n",
    "    \n",
    "    for i in Columns:\n",
    "        tfTrainGeneral[i]=trainTf[i]\n",
    "    \n",
    "    y_pred_texto = svmc.predict(tfTrainGeneral)\n",
    "    \n",
    "    return decode(y_pred_texto[0]), trainIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "InicioPrediccion, matriz = PrediceSpam(['Eres el ganador de un vehículo nuevo solo debes enviar la información de tu tarjeta de crédito'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InicioPrediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema #2:\n",
    "Para el dataset llamado imdb rev.txt desarrolle un clasicador de reviews positivos o negativos, la variable que debe predecir esta codificada como 0 y como 1, donde 0 es un review malo y 1 es un review bueno. Tome en cuenta que este archivo no es un csv y usted debera procesarlo para poder formar una estructura adecuada para la clasificacion, ademas note que esta en ingles, por tal motivo debe utilizar el modelo de lenguaje adecuado. Recuerde usar todos los recursos que conoce sobre\n",
    "Machine Learning para determinar si su programa clasifica adecuadamente, puede usar cualquier clasificador que desee incluso varios si lo considera necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-procesamiento del texto hacia un dataframe de Pandas para mejor manipulacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# archivo-entrada: archivo de texto\n",
    "archivo = open(\"imdb_rev.txt\", \"r\")\n",
    "for linea in archivo.readlines():\n",
    "    lineas.append(linea)\n",
    "archivo.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.DataFrame(lineas,columns=['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos['Calificacion']=(datos['Review'].str.slice(start=-2)).str.strip()\n",
    "datos['Review'] = datos['Review'].str.slice(start = 0, stop = -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Calificacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review Calificacion\n",
       "0    A very, very, very slow-moving, aimless movie ...            0\n",
       "1    Not sure who was more lost - the flat characte...            0\n",
       "2    Attempting artiness with black & white and cle...            0\n",
       "3         Very little music or anything to speak of.              0\n",
       "4    The best scene in the movie was when Gerardo i...            1\n",
       "..                                                 ...          ...\n",
       "995  I just got bored watching Jessice Lange take h...            0\n",
       "996  Unfortunately, any virtue in this film's produ...            0\n",
       "997                   In a word, it is embarrassing.              0\n",
       "998                               Exceptionally bad!              0\n",
       "999  All in all its an insult to one's intelligence...            0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza y creacion de corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0, 1000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', datos['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = datos.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obteniendo training set y test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamos un modelo Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creando matriz de confusion para evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71 15]\n",
      " [50 64]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretacion de la matriz de confusion\n",
    "\n",
    "La exactitud de nuestro modelo realmente es mejorable, pues tiene solo un 67.5% de exactitud. Valdria la pena analizar porque hay una diferencia tan grande. Se procedera a utilizar otra tecnica de Steamming para ver si el modelo mejora usando SnowBall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza y creacion de corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0, 1000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', datos['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    sb = SnowballStemmer(language = 'english')\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    review = [sb.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = datos.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obteniendo training set y test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamos un modelo Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creando matriz de confusion para evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71 15]\n",
      " [49 65]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretacion de la matriz de confusion\n",
    "\n",
    "La exactitud de nuestro modelo realmente no presenta una mejora sustancial al cambiar el metodo de steamming. Solo llega a un 68%. Como comentario para mejorar el modelo seria de usar un ensamble learning entre algunos algoritmos de clasificacion y mejorar esta predicción."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
