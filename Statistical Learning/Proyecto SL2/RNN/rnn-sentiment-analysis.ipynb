{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Sentiment analysis para comentarios de peliculas \n#### Proyecto parte 3\nRuben Gonzalez 20003314"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom sklearn.metrics import roc_auc_score\n\nfrom tensorflow.python.keras.preprocessing.text import Tokenizer\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.python.keras.callbacks import EarlyStopping\n\nfrom keras.optimizers import Adam\n\nimport keras.models\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, GRU, BatchNormalization, GlobalMaxPooling1D, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.initializers import Constant\n\nimport string\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/imdb-reviews-dataset/imdb_reviews_dataset.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Carga y preprocesamiento de datos"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/imdb-reviews-dataset/imdb_reviews_dataset.csv')\ndf.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"  data_type         id  rating  \\\n0     train      pos_0       9   \n1     train  pos_10000       8   \n2     train  pos_10001      10   \n3     train  pos_10002       7   \n4     train  pos_10003       8   \n\n                                                text  \n0  Bromwell High is a cartoon comedy. It ran at t...  \n1  Homelessness (or Houselessness as George Carli...  \n2  Brilliant over-acting by Lesley Ann Warren. Be...  \n3  This is easily the most underrated film inn th...  \n4  This is not the typical Mel Brooks film. It wa...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data_type</th>\n      <th>id</th>\n      <th>rating</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train</td>\n      <td>pos_0</td>\n      <td>9</td>\n      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train</td>\n      <td>pos_10000</td>\n      <td>8</td>\n      <td>Homelessness (or Houselessness as George Carli...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train</td>\n      <td>pos_10001</td>\n      <td>10</td>\n      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train</td>\n      <td>pos_10002</td>\n      <td>7</td>\n      <td>This is easily the most underrated film inn th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train</td>\n      <td>pos_10003</td>\n      <td>8</td>\n      <td>This is not the typical Mel Brooks film. It wa...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rating.value_counts()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"0     50000\n1     10122\n10     9731\n8      5859\n4      5331\n3      4961\n7      4803\n9      4607\n2      4586\nName: rating, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Se remueven los reviews sin rating pues no nos sirven para el analisis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_etiquetado = df[df['rating'] != 0].copy() \ndf_etiquetado.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(50000, 4)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_etiquetado.rating.value_counts()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"1     10122\n10     9731\n8      5859\n4      5331\n3      4961\n7      4803\n9      4607\n2      4586\nName: rating, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Se crea una nueva columna que identifique si el sentimiento es positivo o no usando aquellos comentarios con ranquin mayor o igual a 7 como positivos"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_etiquetado['sentimiento'] = df_etiquetado.rating.apply(lambda x: 1 if x >= 7 else 0)\ndf_etiquetado[\"Length\"] = df_etiquetado['text'].apply(lambda x: len(x.split()))","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_etiquetado.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"  data_type         id  rating  \\\n0     train      pos_0       9   \n1     train  pos_10000       8   \n2     train  pos_10001      10   \n3     train  pos_10002       7   \n4     train  pos_10003       8   \n\n                                                text  sentimiento  Length  \n0  Bromwell High is a cartoon comedy. It ran at t...            1     140  \n1  Homelessness (or Houselessness as George Carli...            1     428  \n2  Brilliant over-acting by Lesley Ann Warren. Be...            1     147  \n3  This is easily the most underrated film inn th...            1     124  \n4  This is not the typical Mel Brooks film. It wa...            1     120  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data_type</th>\n      <th>id</th>\n      <th>rating</th>\n      <th>text</th>\n      <th>sentimiento</th>\n      <th>Length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train</td>\n      <td>pos_0</td>\n      <td>9</td>\n      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n      <td>1</td>\n      <td>140</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train</td>\n      <td>pos_10000</td>\n      <td>8</td>\n      <td>Homelessness (or Houselessness as George Carli...</td>\n      <td>1</td>\n      <td>428</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train</td>\n      <td>pos_10001</td>\n      <td>10</td>\n      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n      <td>1</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train</td>\n      <td>pos_10002</td>\n      <td>7</td>\n      <td>This is easily the most underrated film inn th...</td>\n      <td>1</td>\n      <td>124</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train</td>\n      <td>pos_10003</td>\n      <td>8</td>\n      <td>This is not the typical Mel Brooks film. It wa...</td>\n      <td>1</td>\n      <td>120</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Como el dataset ya esta segmentado en train y test, se usara esa misma segmentacion"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-procesamiento del texto\nSe utiliza word2vec para la tokenizacion de las entradas X"},{"metadata":{"trusted":true},"cell_type":"code","source":"review_lines = list()\nlines = df['text'].values.tolist()\n\nstop_words = set(stopwords.words('english'))\n\nfor line in lines:\n    tokens = word_tokenize(line)\n    tokens = [w.lower() for w in tokens]\n    table = str.maketrans('', '', string.punctuation)\n    stripped = [w.translate(table) for w in tokens]\n    words = [word for word in stripped if word.isalpha()]\n    words = [w for w in words if not w in stop_words]\n    review_lines.append(words)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(review_lines)","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"100000"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nEMBEDDING_DIM = 256\n\nmodel = gensim.models.Word2Vec(sentences=review_lines, size=EMBEDDING_DIM, window=5, workers=4, min_count=5)\nwords = list(model.wv.vocab)\nprint('Tamaño del vocabulario: %d' % len(words))","execution_count":13,"outputs":[{"output_type":"stream","text":"Tamaño del vocabulario: 56449\nCPU times: user 4min 45s, sys: 1.56 s, total: 4min 46s\nWall time: 2min 50s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Almacenamos el vocabulario en el formato requerido para su potencial uso posterior"},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'vocabulario.txt'\nmodel.wv.save_word2vec_format(filename, binary=False)","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recuperacion del vocabulario creado usando word2vec"},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_index = {}\nwith open(os.path.join('./vocabulario.txt')) as fin:\n    for line in fin:\n        values = line.split()\n        if len(values) == 2:\n            print('Num words - ', values[0])\n            print('EMBEDDING_DIM =', values[1])\n            continue\n        word = values[0]\n        coefs = np.asarray(values[1:])\n        embedding_index[word] = coefs","execution_count":15,"outputs":[{"output_type":"stream","text":"Num words -  56449\nEMBEDDING_DIM = 256\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_text_info = df_etiquetado['Length'].describe()\nlen_text_info","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"count    50000.000000\nmean       231.156940\nstd        171.343997\nmin          4.000000\n25%        126.000000\n50%        173.000000\n75%        280.000000\nmax       2470.000000\nName: Length, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set max len for padding\nmax_length = int(len_text_info['mean'] + 2 * len_text_info['std'])\nprint(max_length) # = 200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer_obj = Tokenizer()\ntotal_reviews = df_etiquetado['text'].values\ntokenizer_obj.fit_on_texts(total_reviews)\nsequences = tokenizer_obj.texts_to_sequences(total_reviews)\n\nword_index = tokenizer_obj.word_index\nprint('Encontrados %s tokens.' % len(word_index))\n\nreview_pad = pad_sequences(sequences, maxlen=max_length, padding='post')\nsentiment = df_etiquetado['sentimiento'].values\nprint(review_pad.shape)\nprint(sentiment.shape)","execution_count":16,"outputs":[{"output_type":"stream","text":"Encontrados 124252 tokens.\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'max_length' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-9d6bb015bc22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Encontrados %s tokens.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mreview_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_etiquetado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentimiento'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'max_length' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Diccionario que contiene las palabras unicas con el token asociado\nword_index['the']\n\n# Contiene los registros de texto tokenizados\nreview_pad\n\n#Contiene el arreglo que indica si el sentimiento es positivo (1) o negativo (0)\nsentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_words = len(word_index) + 1\nembedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n\nwords_n = 0\nfinde_n = 0\nfor word, i in word_index.items():\n    words_n += 1\n    if i > num_words:\n        continue\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None:\n        finde_n += 1\n        embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Obteniendo particiones para entrenamiento/validacion/pruebas"},{"metadata":{"trusted":true},"cell_type":"code","source":"review_pad.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(review_pad, sentiment, test_size = 0.02, random_state = 0)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.05, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\nprint(X_val.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creacion del modelo RNN usando GRU\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelo = Sequential()\nembedding_layer = Embedding(\n    num_words,\n    EMBEDDING_DIM,\n    embeddings_initializer=Constant(embedding_matrix),\n    input_length=max_length,\n    trainable=False,\n)\n\nmodelo.add(embedding_layer)\nmodelo.add(BatchNormalization())\nmodelo.add(Dropout(0.2))\nmodelo.add(GRU(units=32))\nmodelo.add(BatchNormalization())\nmodelo.add(Dropout(0.2))\nmodelo.add(Dense(1, activation='sigmoid'))\n\noptimizer = Adam(lr=0.0005)\nmodelo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelo.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Entrenamiento"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Inicio entrenamiento...')\n\nmy_callbacks = [\n    EarlyStopping(patience=10),\n]\nbitacora = modelo.fit(X_train, y_train, batch_size=128, epochs=30, validation_data=(X_val, y_val), verbose=2, callbacks=my_callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Graficando el error y la precision"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(20, 4))\n\naxs[0].plot(bitacora.history['loss'], label='loss')\naxs[0].plot(bitacora.history['val_loss'], label='val_loss')\n\naxs[1].plot(bitacora.history['accuracy'], label='acc')\naxs[1].plot(bitacora.history['val_accuracy'], label='val_acc')\n\nplt.legend();\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Guardando el modelo / Recuperando el modelo\nDado que ya supero el porcentaje minimo de exactitud solicitada, se procedera a almacenar el modelo"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelo.save('RNN-GRUModelo.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cargamos nuevamente el modelo realizado. Activar solo si es necesario\n#from keras.models import load_model\n#modelo = load_model('CNN-Modelo.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Probando con datos de test y validando error/precision"},{"metadata":{"trusted":true},"cell_type":"code","source":"metricasTest=modelo.evaluate(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tiene un error de 0.24 y una precision de 91%"},{"metadata":{},"cell_type":"markdown","source":"## Se procedera a realizar otro modelo esta vez usando BERT Model para ver si se obtienen mejores resultados\n\nInstalando librerias necesarias"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip3 install ktrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os.path\nimport numpy as np\nimport tensorflow as tf\nimport ktrain\nfrom ktrain import text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creando datasets de training y de test"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_etiquetado.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train_bert,  y_train_bert), (X_val_bert, y_val_bert), preproc = text.texts_from_df(df_etiquetado,\n                                                                                     'text',\n                                                                                     label_columns = ['sentimiento'],\n                                                                                     preprocess_mode = 'bert',\n                                                                                     maxlen = 500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Construyendo el modelo BERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"modeloBert = text.text_classifier(name='bert',\n                             train_data=(X_train_bert, y_train_bert),\n                             preproc=preproc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Entrenando el modelo BERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"learner = ktrain.get_learner(model=modeloBert,\n                             train_data=(X_train_bert, y_train_bert),\n                             val_data=(X_val_bert, y_val_bert),\n                             batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.fit_onecycle(lr=2e-5,\n                     epochs=1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}